import torch
import torch.nn as nn
import os
from collections import OrderedDict


# =====================================================================================
# --- æ­¥éª¤ A: ç¡®ä¿æ¨¡å‹å®šä¹‰ä¸ EasyOCR ä¸€è‡´ (ä¸€æ¬¡æ€§ä¿®æ”¹) ---
# è¿™ä¸ªè„šæœ¬ç°åœ¨æ˜¯è‡ªåŒ…å«çš„ï¼ŒåŒ…å«äº†ä¹‹å‰å¯¹ feature_extraction.py çš„ä¿®æ­£ã€‚
# æ‚¨æ— éœ€å†ä¿®æ”¹ä»“åº“çš„å…¶ä»–æ–‡ä»¶ã€‚
# =====================================================================================

class VGG_FeatureExtractor_EasyOCR(nn.Module):
    """ Feature Extractor tailored for EasyOCR's zh_sim_g2.pth model """

    def __init__(self, input_channel, output_channel=256):
        super(VGG_FeatureExtractor_EasyOCR, self).__init__()
        self.ConvNet = nn.Sequential(
            nn.Conv2d(input_channel, 32, 3, 1, 1), nn.ReLU(True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(True),
            nn.MaxPool2d(2, 2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(True),
            nn.Conv2d(128, 128, 3, 1, 1), nn.ReLU(True),
            nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(128, 256, 3, 1, 1, bias=False),
            nn.BatchNorm2d(256), nn.ReLU(True),
            nn.Conv2d(256, 256, 3, 1, 1, bias=False),
            nn.BatchNorm2d(256), nn.ReLU(True),
            nn.MaxPool2d((2, 1), (2, 1)),
            nn.Conv2d(256, output_channel, 2, 1, 0), nn.ReLU(True))


from modules.sequence_modeling import BidirectionalLSTM


class Model(nn.Module):
    """ A simplified Model class definition that matches our needs """

    def __init__(self, opt):
        super(Model, self).__init__()
        self.opt = opt
        # We now use our custom, compatible VGG extractor
        self.FeatureExtraction = VGG_FeatureExtractor_EasyOCR(opt.input_channel, opt.output_channel)
        self.FeatureExtraction_output = opt.output_channel
        self.AdaptiveAvgPool = nn.AdaptiveAvgPool2d((None, 1))
        self.SequenceModeling = nn.Sequential(
            BidirectionalLSTM(self.FeatureExtraction_output, opt.hidden_size, opt.hidden_size),
            BidirectionalLSTM(opt.hidden_size, opt.hidden_size, opt.hidden_size))
        self.SequenceModeling_output = opt.hidden_size
        self.Prediction = nn.Linear(self.SequenceModeling_output, opt.num_class)

    def forward(self, input, text=None, is_train=True):
        visual_feature = self.FeatureExtraction(input)
        visual_feature = self.AdaptiveAvgPool(visual_feature.permute(0, 3, 1, 2))
        visual_feature = visual_feature.squeeze(3)
        contextual_feature = self.SequenceModeling(visual_feature)
        prediction = self.Prediction(contextual_feature.contiguous())
        return prediction


# =====================================================================================
# --- æ­¥éª¤ B: é…ç½®åŒº (æ‚¨å”¯ä¸€éœ€è¦ä¿®æ”¹çš„åœ°æ–¹) ---
# =====================================================================================
class ModelOptions:
    def __init__(self):
        # è¯·å°†æ‚¨è‡ªå·±æ•°æ®é›†çš„ä¸“å±å­—ç¬¦é›†å®Œæ•´åœ°ç²˜è´´åˆ°è¿™é‡Œ
        self.character = "()+123456ABCFHKMNOPSZaeglnuÂ·â†‘â†’â†“å…‰åŠ æ¸©ç‚¹çƒ­ç…§ç‡ƒç”µé€šé«˜"

        # æ¶æ„ä¸ EasyOCR zh_sim_g2.pth å®Œå…¨åŒ¹é…
        self.Prediction = 'CTC'  # ä¿æŒ 'CTC'

        # è¶…å‚æ•°ä¸ EasyOCR zh_sim_g2.pth å®Œå…¨åŒ¹é…
        self.output_channel = 256
        self.hidden_size = 256

        # å…¶ä»–æ ‡å‡†å‚æ•°
        self.input_channel = 1
        self.imgH = 32
        self.imgW = 100
        self.num_class = len(self.character) + 1  # CTC blank token


# =====================================================================================
# --- æ­¥éª¤ C: ä¸€ä½“åŒ–æ‰‹æœ¯è„šæœ¬ ---
# =====================================================================================
def create_compatible_finetune_model(opt, pretrained_model_path, new_model_path):
    print("=" * 50)
    print("--- å¼€å§‹æ‰§è¡Œä¸€ä½“åŒ–æ¨¡å‹æ‰‹æœ¯ ---")
    print("=" * 50)

    # --- 1. åŠ è½½å¹¶è„±å£³ (ç§»é™¤ 'module.' å‰ç¼€) ---
    if not os.path.exists(pretrained_model_path):
        print(f"é”™è¯¯: é¢„è®­ç»ƒæ¨¡å‹ '{pretrained_model_path}' ä¸å­˜åœ¨ã€‚")
        return
    print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {pretrained_model_path}")
    pretrained_state_dict = torch.load(pretrained_model_path, map_location='cpu')
    clean_state_dict = OrderedDict()
    for k, v in pretrained_state_dict.items():
        name = k[7:] if k.startswith('module.') else k
        clean_state_dict[name] = v
    print("æ­¥éª¤ 1/4: 'è„±å£³'å®Œæˆï¼Œå·²å‡€åŒ–å±‚åç§°ã€‚")

    # --- 2. åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹å¹¶æ¢å¤´ (è¿ç§»æƒé‡) ---
    print("\næ­¥éª¤ 2/4: åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹å¹¶å‡†å¤‡'æ¢å¤´'...")
    new_model = Model(opt)
    new_model_state_dict = new_model.state_dict()

    for name, param in clean_state_dict.items():
        if name in new_model_state_dict and new_model_state_dict[name].shape == param.shape:
            new_model_state_dict[name].copy_(param)

    new_model.load_state_dict(new_model_state_dict)
    print(" -> 'æ¢å¤´'å®Œæˆï¼Œå…¼å®¹æƒé‡å·²åŠ è½½åˆ°æ–°æ¨¡å‹ã€‚")

    # --- 3. ä¸ºæ–°æ¨¡å‹ç©¿ä¸Šæ–°å£³ (åŠ å› 'module.' å‰ç¼€) ---
    print("\næ­¥éª¤ 3/4: ä¸ºæ–°æ¨¡å‹'ç©¿ä¸Šæ–°å£³'ä»¥å…¼å®¹DataParallel...")
    final_state_dict = OrderedDict()
    for k, v in new_model.state_dict().items():
        final_state_dict['module.' + k] = v
    print(" -> 'ç©¿å£³'å®Œæˆã€‚")

    # --- 4. ä¿å­˜æœ€ç»ˆæ¨¡å‹ ---
    torch.save(final_state_dict, new_model_path)
    print("\næ­¥éª¤ 4/4: ä¿å­˜æœ€ç»ˆæ¨¡å‹ã€‚")
    print("=" * 50)
    print(f"ğŸ‰ ç»ˆææ‰‹æœ¯æˆåŠŸï¼å¯ä»¥ç›´æ¥ç”¨äºè®­ç»ƒçš„æ¨¡å‹å·²ä¿å­˜è‡³: '{new_model_path}'")
    print("=" * 50)


if __name__ == '__main__':
    # åˆå§‹åŒ–é…ç½®
    config = ModelOptions()

    # å®šä¹‰è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶
    base_model_file = 'zh_sim_g2.pth'
    finetune_starter_file = 'my_finetune_starter_final.pth'  # ä½¿ç”¨æ–°åå­—ä»¥ç¤ºåŒºåˆ«

    # æ‰§è¡Œä¸€ä½“åŒ–æ‰‹æœ¯
    create_compatible_finetune_model(config, base_model_file, finetune_starter_file)